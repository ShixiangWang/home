<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"> 
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
    
    <link rel="stylesheet" href="../../../fonts/academicons-1.8.6/css/academicons.min.css"/>
    <link rel="icon" type="image/png" sizes="32x32" href="../../../logo/bodhi.png"> 
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    
    
    <title>Tensorflow-完整神经网络样例程序 - 王诗翔</title>
    
     
    <meta property="og:title" content="Tensorflow-完整神经网络样例程序 - Shixiang Wang | 王诗翔">
    

    
      
    

    

    
    


<link href='//cdn.bootcss.com/highlight.js/9.12.0/styles/Xcode.min.css' rel='stylesheet' type='text/css' />



    <link rel="stylesheet" href="../../../css/style.css" />
    <link rel="stylesheet" href="../../../css/mystyle.css" /> 
    <link rel="stylesheet" href="../../../css/fonts.css" />
    
<script async src="../../../js/load-typekit.js"></script>


<link rel="stylesheet" href="../../../css/custom.css" />

  </head>
  
  <body class="cn">
    <header class="masthead">
      

<h1><a href="../../../logo/ShixiangWang.png"><img src="../../../logo/ShixiangWang.png" alt="Shixiang Wang" /></a></h1>
<p align="right" style="margin-top:-50px;"><small>><i>上士闻道<br>勤而行之</i></small></p>




      <nav class="menu">
        <input id="menu-check" type="checkbox" />
        <label id="menu-label" for="menu-check" class="unselectable">
          <span class="icon close-icon">✕</span>
          <span class="icon open-icon">☰</span>
          <span class="text">Menu</span>
        </label>
        <ul>
        
        
        <li><a href="../../../">首页</a></li>
        
        <li><a href="../../../cn/about/">关于</a></li>
        
        <li><a href="../../../cn/post/">博客</a></li>
        
        <li><a href="../../../cn/read/">读书</a></li>
        
        <li><a href="../../../cn/writing">写作</a></li>
        
        <li><a href="../../../cn/research/">研究</a></li>
        
        <li><a href="../../../cn/tools/">工具</a></li>
        
        <li><a href="../../../cn/cv-cn/shixiang">简历</a></li>
        
        <li><a href="../../../logo/qrcode.jpg">公众号</a></li>
        
        <li><a href="https://www.zhihu.com/people/shixiangwang">知乎</a></li>
        
        <li><a href="../../../cn/mark">推荐阅读</a></li>
        
        <li><a href="../../../en/">English</a></li>
        
        <li><a href="../../../categories/">分类</a></li>
        
        <li><a href="../../../tags/">标签</a></li>
        
        

<li class="menu-extra"></li>



<li><a href="https://github.com/ShixiangWang/home/edit/master/content/cn/post/2019-07-04-tensorflow-an-example.md" target="_blank">编辑</a></li>


<li><a href="../../../cn/index.xml" type="application/rss+xml" title="RSS feed">订阅</a></li>

<li><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="Attribution-NonCommercial-ShareAlike 4.0 International">版权</a></li>


        </ul>
      </nav>
    </header>

    <article class="main">
      <header class="title">
        

<h1>Tensorflow-完整神经网络样例程序</h1>



<h3>王诗翔 &middot 
2019-07-04</h3> 


<p style="text-align:right;">
  分类:
  
    <a href="../../../categories/ml">ml</a> &nbsp
  
  <br>
  标签:
  
    <a href="../../../tags/machine-learning">machine-learning</a> &nbsp
  
    <a href="../../../tags/tensorflow">tensorflow</a> &nbsp
  
</p>



   
  


      </header>


<p>来源：《Tensorflow实战Google深度学习框架》第二版，第三章</p>
<p>略修改。</p>
<p>总结而言有三个步骤：</p>
<ol>
<li>定义神经网络的结构和前向传播的输出结果</li>
<li>定义损失函数以及选择反向传播优化的算法</li>
<li>生成会话并在训练集上反复运行反向传播优化算法</li>
</ol>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf 

<span style="color:#75715e"># 通过 NumPy 生成模拟数据集</span>
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> RandomState

<span style="color:#75715e"># 定义训练数据的 batch 大小</span>
batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>

<span style="color:#75715e"># 定义神经网络的参数</span>
w1 <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>random_normal([<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>], stddev<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, seed<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
w2 <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>random_normal([<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">1</span>], stddev<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, seed<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))

<span style="color:#75715e"># shape 的一个维度使用 None 可以方便使用不同的 batch 大小</span>
<span style="color:#75715e"># 在训练时需要把数据分成比较小的 batch</span>
<span style="color:#75715e"># 但在测试时，可以一次性使用全部的数据</span>
<span style="color:#75715e"># 在数据较小时这样方便测试，但数据很大放入一个 batch 可能会内存溢出</span>
x  <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, shape<span style="color:#f92672">=</span>(None, <span style="color:#ae81ff">2</span>), name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;x-input&#34;</span>)
y_ <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, shape<span style="color:#f92672">=</span>(None, <span style="color:#ae81ff">1</span>), name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;y-input&#34;</span>)

<span style="color:#75715e"># 定义神经网络前向传播过程</span>
a <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>matmul(x, w1)
y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>matmul(a, w2)

<span style="color:#75715e"># 定义损失函数和反向传播算法</span>
y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>sigmoid(y)
cross_entropy <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>tf<span style="color:#f92672">.</span>reduce_mean(
    y_ <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>log(tf<span style="color:#f92672">.</span>clip_by_value(y, <span style="color:#ae81ff">1e-10</span>, <span style="color:#ae81ff">1.0</span>))
    <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>y_) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>log(tf<span style="color:#f92672">.</span>clip_by_value(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>y, <span style="color:#ae81ff">1e-10</span>, <span style="color:#ae81ff">1.0</span>))
)
train_step <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>AdamOptimizer(<span style="color:#ae81ff">0.001</span>)<span style="color:#f92672">.</span>minimize(cross_entropy)

<span style="color:#75715e"># 随机生成一个模拟数据集</span>
rdm <span style="color:#f92672">=</span> RandomState(<span style="color:#ae81ff">1</span>)
dataset_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>
X <span style="color:#f92672">=</span> rdm<span style="color:#f92672">.</span>rand(dataset_size, <span style="color:#ae81ff">2</span>)

<span style="color:#75715e"># 定义规则来给出样本的标签。这里 x1+x2&lt;1 的样例认为是正样本（如零件合格）</span>
<span style="color:#75715e"># 而其他为负样本。</span>
<span style="color:#75715e"># 大部分解决分类问题的神经网络都会采用 0（负样本） 和 1（正样本） 的表示方法</span>
Y <span style="color:#f92672">=</span> [[int(x1<span style="color:#f92672">+</span>x2<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span>)] <span style="color:#66d9ef">for</span> (x1, x2) <span style="color:#f92672">in</span> X]

<span style="color:#75715e"># 创建一个会话运行 tensorflow</span>
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
    init_op <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>global_variables_initializer()
    <span style="color:#75715e"># 初始化变量</span>
    sess<span style="color:#f92672">.</span>run(init_op)

    <span style="color:#75715e"># 训练之前神经网络参数的值</span>
    <span style="color:#66d9ef">print</span>(sess<span style="color:#f92672">.</span>run(w1))
    <span style="color:#66d9ef">print</span>(sess<span style="color:#f92672">.</span>run(w2))

    <span style="color:#75715e"># 设定训练的次数</span>
    STEPS <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(STEPS):
        <span style="color:#75715e"># 每次选出 batch_size 个样本进行训练</span>
        start <span style="color:#f92672">=</span> (i <span style="color:#f92672">*</span> batch_size) <span style="color:#f92672">%</span> dataset_size
        end <span style="color:#f92672">=</span> min(start<span style="color:#f92672">+</span>batch_size, dataset_size)

        <span style="color:#75715e"># 通过选取的样本训练神经网络并更新参数</span>
        sess<span style="color:#f92672">.</span>run(train_step, 
                feed_dict<span style="color:#f92672">=</span>{x: X[start:end], y_: Y[start:end]})
        
        <span style="color:#66d9ef">if</span> i <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">or</span> (i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">%</span> <span style="color:#ae81ff">1000</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
            <span style="color:#75715e"># 每隔一段时间计算在所有数据上的交叉熵并输出</span>
            total_cross_entropy <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run(
                cross_entropy, feed_dict<span style="color:#f92672">=</span>{x: X, y_: Y}
            )
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;After </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> training step(s), cross entropy on all data is </span><span style="color:#e6db74">%g</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (i <span style="color:#66d9ef">if</span> i<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span> <span style="color:#66d9ef">else</span> i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, total_cross_entropy))

    <span style="color:#75715e"># 更新后的神经网络参数值</span>
    <span style="color:#66d9ef">print</span>(sess<span style="color:#f92672">.</span>run(w1))
    <span style="color:#66d9ef">print</span>(sess<span style="color:#f92672">.</span>run(w2))
</code></pre></div><p>运行结果：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ python tf_an_example.py 
WARNING:tensorflow:From /public/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with <span style="color:#f92672">(</span>from tensorflow.python.framework.ops<span style="color:#f92672">)</span> is deprecated and will be removed in a future version.
Instructions <span style="color:#66d9ef">for</span> updating:
Colocations handled automatically by placer.
2019-07-04 14:24:28.939818: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94<span style="color:#f92672">]</span> CPU Frequency: <span style="color:#ae81ff">1895430000</span> Hz
2019-07-04 14:24:28.941254: I tensorflow/compiler/xla/service/service.cc:150<span style="color:#f92672">]</span> XLA service 0x7fa598f260a0 executing computations on platform Host. Devices:
2019-07-04 14:24:28.941301: I tensorflow/compiler/xla/service/service.cc:158<span style="color:#f92672">]</span>   StreamExecutor device <span style="color:#f92672">(</span>0<span style="color:#f92672">)</span>: &lt;undefined&gt;, &lt;undefined&gt;
OMP: Info <span style="color:#75715e">#212: KMP_AFFINITY: decoding x2APIC ids.</span>
OMP: Info <span style="color:#75715e">#213: KMP_AFFINITY: cpuid leaf 11 not supported - decoding legacy APIC ids.</span>
OMP: Info <span style="color:#75715e">#149: KMP_AFFINITY: Affinity capable, using global cpuid info</span>
OMP: Info <span style="color:#75715e">#154: KMP_AFFINITY: Initial OS proc set respected: 0-7</span>
OMP: Info <span style="color:#75715e">#156: KMP_AFFINITY: 8 available OS procs</span>
OMP: Info <span style="color:#75715e">#157: KMP_AFFINITY: Uniform topology</span>
OMP: Info <span style="color:#75715e">#159: KMP_AFFINITY: 2 packages x 4 cores/pkg x 1 threads/core (8 total cores)</span>
OMP: Info <span style="color:#75715e">#214: KMP_AFFINITY: OS proc to physical thread map:</span>
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0</span> 
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1</span> 
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2</span> 
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3</span> 
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 4 maps to package 1 core 0</span> 
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 5 maps to package 1 core 1</span> 
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 6 maps to package 1 core 2</span> 
OMP: Info <span style="color:#75715e">#171: KMP_AFFINITY: OS proc 7 maps to package 1 core 3</span> 
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7723 thread 0 bound to OS proc set 0</span>
2019-07-04 14:24:28.943084: I tensorflow/core/common_runtime/process_util.cc:71<span style="color:#f92672">]</span> Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads <span style="color:#66d9ef">for</span> best performance.
<span style="color:#f92672">[[</span>-0.8113182   1.4845988   0.06532937<span style="color:#f92672">]</span>
 <span style="color:#f92672">[</span>-2.4427042   0.0992484   0.5912243 <span style="color:#f92672">]]</span>
<span style="color:#f92672">[[</span>-0.8113182 <span style="color:#f92672">]</span>
 <span style="color:#f92672">[</span> 1.4845988 <span style="color:#f92672">]</span>
 <span style="color:#f92672">[</span> 0.06532937<span style="color:#f92672">]]</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7766 thread 1 bound to OS proc set 4</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7787 thread 2 bound to OS proc set 1</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7788 thread 3 bound to OS proc set 5</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7790 thread 5 bound to OS proc set 6</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7789 thread 4 bound to OS proc set 2</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7792 thread 6 bound to OS proc set 3</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7795 thread 7 bound to OS proc set 7</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7797 thread 8 bound to OS proc set 0</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7767 thread 9 bound to OS proc set 4</span>
After <span style="color:#ae81ff">0</span> training step<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>, cross entropy on all data is 1.89805
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7809 thread 10 bound to OS proc set 1</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7812 thread 11 bound to OS proc set 5</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7813 thread 12 bound to OS proc set 2</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7814 thread 13 bound to OS proc set 6</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7817 thread 15 bound to OS proc set 7</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7816 thread 14 bound to OS proc set 3</span>
OMP: Info <span style="color:#75715e">#250: KMP_AFFINITY: pid 7723 tid 7818 thread 16 bound to OS proc set 0</span>
After <span style="color:#ae81ff">1000</span> training step<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>, cross entropy on all data is 0.655198
After <span style="color:#ae81ff">2000</span> training step<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>, cross entropy on all data is 0.626185
After <span style="color:#ae81ff">3000</span> training step<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>, cross entropy on all data is 0.615106
After <span style="color:#ae81ff">4000</span> training step<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>, cross entropy on all data is 0.610311
After <span style="color:#ae81ff">5000</span> training step<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>, cross entropy on all data is 0.608681
<span style="color:#f92672">[[</span> 0.02476973  0.56948674  1.6921943 <span style="color:#f92672">]</span>
 <span style="color:#f92672">[</span>-2.1977348  -0.23668918  1.1143894 <span style="color:#f92672">]]</span>
<span style="color:#f92672">[[</span>-0.4554469 <span style="color:#f92672">]</span>
 <span style="color:#f92672">[</span> 0.49110925<span style="color:#f92672">]</span>
 <span style="color:#f92672">[</span>-0.9811033 <span style="color:#f92672">]]</span>
</code></pre></div><p>还行吧，先照虎画猫。</p>


  <footer>
  
<nav class="post-nav">
  <span class="nav-prev">&larr; <a href="../../../cn/post/2019-06-21-baseplot-multiplots/">R传统图形绘制多图</a></span>
  <span class="nav-next"><a href="../../../cn/post/2019-07-07-use-rstatix/">管道统计分析——rstatix使用指南</a> &rarr;</span>
</nav>
<script type="text/javascript">
document.addEventListener('keyup', function(e) {
  if (e.target.nodeName.toUpperCase() != 'BODY') return;
  var url = false;
  if (e.which == 37) {  
    
    url = '\/cn\/post\/2019-06-21-baseplot-multiplots\/';
    
  } else if (e.which == 39) {  
    
    url = '\/cn\/post\/2019-07-07-use-rstatix\/';
    
  }
  if (url) window.location = url;
});
</script>





<div id="gitalk-container"></div>
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js"></script>
<script>
  const gitalk = new Gitalk({
    clientID: 'eed477936be7b88a8455',
    clientSecret: '32b5dde22f3c95c4fad400a31632e34221b07e83',
    repo: 'home',
    owner: 'ShixiangWang',
    admin: ['ShixiangWang'],
    id: md5(window.location.pathname), 
    distractionFreeMode: false 
  });
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('gitalk-container').innerHTML = 'Gitalk comments not available by default when the website is previewed locally.';
      return;
    }
    gitalk.render('gitalk-container');
  })();
</script>





<script async src="../../../js/fix-toc.js"></script>

<script async src="../../../js/center-img.js"></script>

<script async src="../../../js/right-quote.js"></script>

<script async src="../../../js/no-highlight.js"></script>

<script async src="../../../js/fix-footnote.js"></script>

<script async src="../../../js/math-code.js"></script>

<script async src="../../../js/external-link.js"></script>

<script async src="../../../js/alt-title.js"></script>

<script async src="../../../js/header-link.js"></script>


<script src="//yihui.org/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script async src="//yihui.org/js/center-img.js"></script>

  



<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/tex.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>




  
  
  

  <div class="copyright"><a href="mailto:w_shixiang@163.com"><i class='far fa-envelope fa-1x'></i></a> · <a href="https://github.com/ShixiangWang"><i class='fab fa-github fa-1x'></i></a> · <a href="https://stackoverflow.com/users/7662327/shixiang-wang"><i class='fab fa-stack-overflow fa-1x'></i></a> · <a href="https://scholar.google.com/citations?user=FvNp0NkAAAAJ&amp;hl=zh-CN"><i class='ai ai-google-scholar ai-1x'></i></a> · <a href="https://orcid.org/0000-0001-9855-7357"><i class='ai ai-orcid ai-1x'></i></a> · <a href="https://www.researchgate.net/profile/Wang_Shixiang4"><i class='ai ai-researchgate ai-1x'></i></a> <br> 本站由 <a href="https://gohugo.io">Hugo</a> 和 <a href="https://bookdown.org/yihui/blogdown/">Blogdown</a> 强力驱动 © <a href="../../../">王诗翔</a> 2017 - 2020 </div>
  
  

  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=56h9es09xn7&amp;m=6&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=1" async="async"></script>
  </footer>
  </article>
  
  </body>
</html>

